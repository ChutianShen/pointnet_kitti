{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_h5(filepath, content):\n",
    "    #imgData = np.zeros((30, 3, 128, 256))\n",
    "    imgData = content\n",
    "    f = h5py.File(filepath, 'w')\n",
    "    f['data'] = imgData\n",
    "    f['labels'] = range(100)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_h5(filepath):\n",
    "    f = h5py.File(filepath, 'r')\n",
    "    f.keys()\n",
    "    a = f['data'][:]\n",
    "    b = f['label'][:]\n",
    "    f.close()\n",
    "    return a, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file_path = \"./indoor3d_sem_seg_hdf5_data/\"\n",
    "filename = \"ply_data_all_0.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, label = read_h5(test_file_path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(1000, 4096, 9) (1000, 4096)\n",
      "[ 0.153       0.47799999  0.051       0.40000001  0.39215687  0.34509805\n",
      "  0.12577319  0.22026333  0.01600753] 1\n"
     ]
    }
   ],
   "source": [
    "print (type(data), type(label))\n",
    "print (data.shape, label.shape)\n",
    "print (data[0][0], label[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pykitti\n",
    "\n",
    "# Change this to the directory where you store KITTI data\n",
    "#basedir = '/Users/kevin_sct/deepLearningStudy/rawdata'\n",
    "basedir = '/Users/kevin_sct/deepLearningStudy/kitti-dataset/KITTI-Dataset-master/data'\n",
    "\n",
    "def load_dataset(date, drive, calibrated=False, frame_range=None):\n",
    "    \"\"\"\n",
    "    Loads the dataset with `date` and `drive`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    date        : Dataset creation date.\n",
    "    drive       : Dataset drive.\n",
    "    calibrated  : Flag indicating if we need to parse calibration data. Defaults to `False`.\n",
    "    frame_range : Range of frames. Defaults to `None`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Loaded dataset of type `raw`.\n",
    "    \"\"\"\n",
    "    dataset = pykitti.raw(basedir, date, drive)\n",
    "\n",
    "    # Load the data\n",
    "    if calibrated:\n",
    "        dataset.load_calib()  # Calibration data are accessible as named tuples\n",
    "\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    print('\\nDrive: ' + str(dataset.drive))\n",
    "    print('\\nFrame range: ' + str(dataset.frames))\n",
    "\n",
    "    if calibrated:\n",
    "        print('\\nIMU-to-Velodyne transformation:\\n' + str(dataset.calib.T_velo_imu))\n",
    "        print('\\nGray stereo pair baseline [m]: ' + str(dataset.calib.b_gray))\n",
    "        print('\\nRGB stereo pair baseline [m]: ' + str(dataset.calib.b_rgb))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-72ff404d3d33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparseTrackletXML\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxmlParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_tracklets_for_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxml_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mLoads\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0malso\u001b[0m \u001b[0mreferred\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtracklets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving\u001b[0m \u001b[0mthem\u001b[0m \u001b[0mindividually\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'source'"
     ]
    }
   ],
   "source": [
    "from source import parseTrackletXML as xmlParser\n",
    "\n",
    "def load_tracklets_for_frames(n_frames, xml_path):\n",
    "    \"\"\"\n",
    "    Loads dataset labels also referred to as tracklets, saving them individually for each frame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_frames    : Number of frames in the dataset.\n",
    "    xml_path    : Path to the tracklets XML.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple of dictionaries with integer keys corresponding to absolute frame numbers and arrays as values. First array\n",
    "    contains coordinates of bounding box vertices for each object in the frame, and the second array contains objects\n",
    "    types as strings.\n",
    "    \"\"\"\n",
    "    tracklets = xmlParser.parseXML(xml_path)\n",
    "\n",
    "    frame_tracklets = {}\n",
    "    frame_tracklets_types = {}\n",
    "    for i in range(n_frames):\n",
    "        frame_tracklets[i] = []\n",
    "        frame_tracklets_types[i] = []\n",
    "\n",
    "    # loop over tracklets\n",
    "    for i, tracklet in enumerate(tracklets):\n",
    "        # this part is inspired by kitti object development kit matlab code: computeBox3D\n",
    "        h, w, l = tracklet.size\n",
    "        # in velodyne coordinates around zero point and without orientation yet\n",
    "        trackletBox = np.array([\n",
    "            [-l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2],\n",
    "            [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2],\n",
    "            [0.0, 0.0, 0.0, 0.0, h, h, h, h]\n",
    "        ])\n",
    "        # loop over all data in tracklet\n",
    "        for translation, rotation, state, occlusion, truncation, amtOcclusion, amtBorders, absoluteFrameNumber in tracklet:\n",
    "            # determine if object is in the image; otherwise continue\n",
    "            if truncation not in (xmlParser.TRUNC_IN_IMAGE, xmlParser.TRUNC_TRUNCATED):\n",
    "                continue\n",
    "            # re-create 3D bounding box in velodyne coordinate system\n",
    "            yaw = rotation[2]  # other rotations are supposedly 0\n",
    "            assert np.abs(rotation[:2]).sum() == 0, 'object rotations other than yaw given!'\n",
    "            rotMat = np.array([\n",
    "                [np.cos(yaw), -np.sin(yaw), 0.0],\n",
    "                [np.sin(yaw), np.cos(yaw), 0.0],\n",
    "                [0.0, 0.0, 1.0]\n",
    "            ])\n",
    "            cornerPosInVelo = np.dot(rotMat, trackletBox) + np.tile(translation, (8, 1)).T\n",
    "            frame_tracklets[absoluteFrameNumber] = frame_tracklets[absoluteFrameNumber] + [cornerPosInVelo]\n",
    "            frame_tracklets_types[absoluteFrameNumber] = frame_tracklets_types[absoluteFrameNumber] + [\n",
    "                tracklet.objectType]\n",
    "\n",
    "    return (frame_tracklets, frame_tracklets_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = '2011_09_26'\n",
    "drive = '0001'\n",
    "dataset = load_dataset(date, drive)\n",
    "tracklet_rects, tracklet_types = load_tracklets_for_frames(len(list(dataset.velo)), 'data/{}/{}_drive_{}_sync/tracklet_labels.xml'.format(date, date, drive))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
